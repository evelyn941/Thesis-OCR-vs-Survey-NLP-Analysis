{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a425c526-258d-412c-8274-248b93c30e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "BASE_DIR = r\"D:\\1909term-thesis\\thesis\\ReviewsCrawler\"\n",
    "df = pd.read_csv(fr\"{BASE_DIR}\\clauses_pred_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a9e9ef-8bbb-4ef7-a7a3-07ff802b1be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>file_name</th>\n",
       "      <th>rateDate</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rateDate_parsed</th>\n",
       "      <th>review_length</th>\n",
       "      <th>clause</th>\n",
       "      <th>domain_pred</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>一直喜欢这件衣服</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>一直不降价</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>终于逮住了</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>特卖会</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>79买的</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>真香</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>留着开春穿</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>优衣库的衣服真心不错</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>值得够买呀</td>\n",
       "      <td>Value Perception</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>浪里个浪</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...</td>\n",
       "      <td>2021-01-08 07:59:09</td>\n",
       "      <td>65</td>\n",
       "      <td>蛮不错</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>质地很柔软，不是容易皱的材质，等天气暖了穿</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>21</td>\n",
       "      <td>质地很柔软</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>质地很柔软，不是容易皱的材质，等天气暖了穿</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>21</td>\n",
       "      <td>不是容易皱的材质</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>质地很柔软，不是容易皱的材质，等天气暖了穿</td>\n",
       "      <td>2020-12-13 21:21:05</td>\n",
       "      <td>21</td>\n",
       "      <td>等天气暖了穿</td>\n",
       "      <td>Functionality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-16 12:31:51</td>\n",
       "      <td>好看面料舒服</td>\n",
       "      <td>2020-09-16 12:31:51</td>\n",
       "      <td>6</td>\n",
       "      <td>好看面料舒服</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-15 19:29:21</td>\n",
       "      <td>我觉得一般</td>\n",
       "      <td>2020-09-15 19:29:21</td>\n",
       "      <td>5</td>\n",
       "      <td>我觉得一般</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>39</td>\n",
       "      <td>U家的T恤穿M码的</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>39</td>\n",
       "      <td>但是衬衣买M的有点紧了</td>\n",
       "      <td>Size &amp; Fit</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>39</td>\n",
       "      <td>下次要买大一码</td>\n",
       "      <td>Size &amp; Fit</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UNIQLO_female</td>\n",
       "      <td>UNIQLO_blouse_female</td>\n",
       "      <td>blouse_611817827239.csv</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服</td>\n",
       "      <td>2020-09-13 22:10:05</td>\n",
       "      <td>39</td>\n",
       "      <td>质量不错</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender              category                file_name  \\\n",
       "0   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "1   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "2   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "3   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "4   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "5   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "6   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "7   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "8   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "9   UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "10  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "11  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "12  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "13  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "14  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "15  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "16  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "17  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "18  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "19  UNIQLO_female  UNIQLO_blouse_female  blouse_611817827239.csv   \n",
       "\n",
       "               rateDate                                        review_text  \\\n",
       "0   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "1   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "2   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "3   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "4   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "5   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "6   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "7   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "8   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "9   2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "10  2021-01-08 07:59:09  一直喜欢这件衣服，一直不降价，终于逮住了，特卖会，79买的，真香，留着开春穿，优衣库的衣服真...   \n",
       "11  2020-12-13 21:21:05                              质地很柔软，不是容易皱的材质，等天气暖了穿   \n",
       "12  2020-12-13 21:21:05                              质地很柔软，不是容易皱的材质，等天气暖了穿   \n",
       "13  2020-12-13 21:21:05                              质地很柔软，不是容易皱的材质，等天气暖了穿   \n",
       "14  2020-09-16 12:31:51                                             好看面料舒服   \n",
       "15  2020-09-15 19:29:21                                              我觉得一般   \n",
       "16  2020-09-13 22:10:05            U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服   \n",
       "17  2020-09-13 22:10:05            U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服   \n",
       "18  2020-09-13 22:10:05            U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服   \n",
       "19  2020-09-13 22:10:05            U家的T恤穿M码的，但是衬衣买M的有点紧了，下次要买大一码，质量不错，穿着舒服   \n",
       "\n",
       "        rateDate_parsed  review_length       clause       domain_pred  \\\n",
       "0   2021-01-08 07:59:09             65     一直喜欢这件衣服             Other   \n",
       "1   2021-01-08 07:59:09             65        一直不降价             Other   \n",
       "2   2021-01-08 07:59:09             65        终于逮住了             Other   \n",
       "3   2021-01-08 07:59:09             65          特卖会             Other   \n",
       "4   2021-01-08 07:59:09             65         79买的             Other   \n",
       "5   2021-01-08 07:59:09             65           真香             Other   \n",
       "6   2021-01-08 07:59:09             65        留着开春穿             Other   \n",
       "7   2021-01-08 07:59:09             65   优衣库的衣服真心不错             Other   \n",
       "8   2021-01-08 07:59:09             65        值得够买呀  Value Perception   \n",
       "9   2021-01-08 07:59:09             65         浪里个浪             Other   \n",
       "10  2021-01-08 07:59:09             65          蛮不错             Other   \n",
       "11  2020-12-13 21:21:05             21        质地很柔软   Product Quality   \n",
       "12  2020-12-13 21:21:05             21     不是容易皱的材质   Product Quality   \n",
       "13  2020-12-13 21:21:05             21       等天气暖了穿     Functionality   \n",
       "14  2020-09-16 12:31:51              6       好看面料舒服   Product Quality   \n",
       "15  2020-09-15 19:29:21              5        我觉得一般             Other   \n",
       "16  2020-09-13 22:10:05             39    U家的T恤穿M码的             Other   \n",
       "17  2020-09-13 22:10:05             39  但是衬衣买M的有点紧了        Size & Fit   \n",
       "18  2020-09-13 22:10:05             39      下次要买大一码        Size & Fit   \n",
       "19  2020-09-13 22:10:05             39         质量不错   Product Quality   \n",
       "\n",
       "    review_id  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          1  \n",
       "12          1  \n",
       "13          1  \n",
       "14          2  \n",
       "15          3  \n",
       "16          4  \n",
       "17          4  \n",
       "18          4  \n",
       "19          4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e210a55d-b245-4048-9e7e-cf059278185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Create a review_id\n",
    "# ============================================================\n",
    "df[\"review_id\"] = (\n",
    "    df[[\"file_name\", \"rateDate_parsed\", \"review_text\"]]\n",
    "    .astype(str)\n",
    "    .agg(\"||\".join, axis=1)\n",
    "    .factorize()[0]\n",
    ")\n",
    "\n",
    "# List of domains\n",
    "DOMAINS = [\"Product Quality\", \"Aesthetic Attributes\", \"Functionality\", \"Size & Fit\", \"Value Perception\"]\n",
    "OTHER_LABEL = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047a46bd-9ccf-4f8f-bc24-e67dc364ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Filtering Summary ===\n",
      "Total clauses before filtering reviews-only-'other': 135252\n",
      "Total clauses after filtering: 112204\n",
      "Total reviews before filtering: 42107\n",
      "Reviews containing ONLY 'other' domain: 9830\n",
      "Total reviews retained (at least one product domain): 32277\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. Remove reviews that contain only 'other' domains\n",
    "# ============================================================\n",
    "\n",
    "# Determine domain set for each review\n",
    "review_domain_set = (\n",
    "    df.groupby(\"review_id\")[\"domain_pred\"]\n",
    "      .apply(set)\n",
    "      .reset_index(name=\"domain_set\")\n",
    ")\n",
    "\n",
    "# Reviews that contain ONLY 'other' domain\n",
    "reviews_only_other = review_domain_set[\n",
    "    review_domain_set[\"domain_set\"].apply(lambda s: s.issubset({OTHER_LABEL}))\n",
    "][\"review_id\"]\n",
    "\n",
    "num_reviews_only_other = len(reviews_only_other)\n",
    "\n",
    "# Reviews that contain at least one non-'other' domain\n",
    "valid_review_ids = review_domain_set[\n",
    "    review_domain_set[\"domain_set\"].apply(lambda s: any(d != OTHER_LABEL for d in s))\n",
    "][\"review_id\"]\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df[df[\"review_id\"].isin(valid_review_ids)].copy()\n",
    "\n",
    "# ============================================================\n",
    "# Printing summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== Filtering Summary ===\")\n",
    "print(f\"Total clauses before filtering reviews-only-'other': {len(df)}\")\n",
    "print(f\"Total clauses after filtering: {len(df_filtered)}\")\n",
    "\n",
    "print(f\"Total reviews before filtering: {df['review_id'].nunique()}\")\n",
    "print(f\"Reviews containing ONLY 'other' domain: {num_reviews_only_other}\")\n",
    "print(f\"Total reviews retained (at least one product domain): {df_filtered['review_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb60417-e0fd-4c76-89bc-6496445f059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Domain Summary Table:\n",
      "                      count  proportion\n",
      "domain_pred                            \n",
      "Aesthetic Attributes  14997      0.1337\n",
      "Functionality          4446      0.0396\n",
      "Other                 49039      0.4371\n",
      "Product Quality       23146      0.2063\n",
      "Size & Fit            15227      0.1357\n",
      "Value Perception       5349      0.0477\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. Data Summary\n",
    "# ============================================================\n",
    "\n",
    "domain_counts = df_filtered[\"domain_pred\"].value_counts().sort_index()\n",
    "domain_proportions = (domain_counts / domain_counts.sum()).round(4)\n",
    "\n",
    "domain_summary = pd.DataFrame({\n",
    "    \"count\": domain_counts,\n",
    "    \"proportion\": domain_proportions\n",
    "})\n",
    "\n",
    "print(\"\\nDomain Summary Table:\")\n",
    "print(domain_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4f64ec-0d77-4112-be09-63c2b55d5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Domain Summary Table:\n",
      "                      count  proportion\n",
      "Product Quality       23146    0.366437\n",
      "Aesthetic Attributes  14997    0.237426\n",
      "Functionality          4446    0.070387\n",
      "Size & Fit            15227    0.241067\n",
      "Value Perception       5349    0.084683\n",
      "\n",
      "=== Construct Coverage Index (CCI) ===\n",
      "Domain-level CCI(d):\n",
      "  Product Quality: 1.832\n",
      "  Aesthetic Attributes: 1.187\n",
      "  Functionality: 0.352\n",
      "  Size & Fit: 1.205\n",
      "  Value Perception: 0.423\n",
      "\n",
      "L1 distance between OCR and survey distributions: 0.4899\n",
      "Global CCI (similarity index): 0.755\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. Construct Coverage Index (CCI)\n",
    "# ============================================================\n",
    "df_non_other = df_filtered[df_filtered[\"domain_pred\"] != OTHER_LABEL].copy()\n",
    "\n",
    "# --- 4.1 OCR-derived domain proportions (excluding 'Other') ---\n",
    "def compute_ocr_proportions(df_non_other, domains):\n",
    "    # Count only over df_non_other (no 'Other')\n",
    "    counts = (\n",
    "        df_non_other[\"domain_pred\"]\n",
    "        .value_counts()\n",
    "        .reindex(domains, fill_value=0)\n",
    "    )\n",
    "    total = counts.sum()\n",
    "    p_ocr = (counts / total).to_dict()\n",
    "    return counts, p_ocr\n",
    "\n",
    "ocr_counts, p_ocr = compute_ocr_proportions(df_non_other, DOMAINS)\n",
    "print(\"\\nDomain Summary Table:\")\n",
    "print(pd.DataFrame({\n",
    "    \"count\": ocr_counts,\n",
    "    \"proportion\": p_ocr\n",
    "}))\n",
    "\n",
    "# --- 4.2 Survey-derived domain proportions (user must fill) ---\n",
    "# IMPORTANT: keys must match DOMAINS exactly\n",
    "p_survey = {\n",
    "    \"Product Quality\":      0.20,\n",
    "    \"Aesthetic Attributes\": 0.20,\n",
    "    \"Functionality\":        0.20,\n",
    "    \"Size & Fit\":           0.20,\n",
    "    \"Value Perception\":     0.20,\n",
    "}\n",
    "\n",
    "# Sanity check: should sum to 1\n",
    "assert abs(sum(p_survey[d] for d in DOMAINS) - 1.0) < 1e-6, \"Survey proportions must sum to 1.\"\n",
    "\n",
    "# --- 4.3 CCI-domain and global CCI ---\n",
    "def compute_cci(p_ocr, p_survey, domains):\n",
    "    \"\"\"\n",
    "    Domain-level CCI(d) = p_ocr[d] / p_survey[d]\n",
    "    Global CCI (similarity) = 1 - 0.5 * sum_d |p_ocr[d] - p_survey[d]|\n",
    "    \"\"\"\n",
    "    cci_domain = {}\n",
    "    for d in domains:\n",
    "        if p_survey[d] > 0:\n",
    "            cci_domain[d] = p_ocr[d] / p_survey[d]\n",
    "        else:\n",
    "            cci_domain[d] = np.nan  # or handle special case\n",
    "\n",
    "    l1_distance = sum(abs(p_ocr[d] - p_survey[d]) for d in domains)\n",
    "    cci_global = 1 - 0.5 * l1_distance  # in [0,1]\n",
    "\n",
    "    return cci_domain, cci_global, l1_distance\n",
    "\n",
    "cci_domain, cci_global, l1_distance = compute_cci(p_ocr, p_survey, DOMAINS)\n",
    "\n",
    "print(\"\\n=== Construct Coverage Index (CCI) ===\")\n",
    "print(\"Domain-level CCI(d):\")\n",
    "for d in DOMAINS:\n",
    "    print(f\"  {d}: {cci_domain[d]:.3f}\")\n",
    "print(f\"\\nL1 distance between OCR and survey distributions: {l1_distance:.4f}\")\n",
    "print(f\"Global CCI (similarity index): {cci_global:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d79abba2-b221-4a6d-a507-8866e3e31093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variance Gap Index (VGI) ===\n",
      "Raw variances per domain:\n",
      "  Product Quality: 0.1692\n",
      "  Aesthetic Attributes: 0.1305\n",
      "  Functionality: 0.0414\n",
      "  Size & Fit: 0.1331\n",
      "  Value Perception: 0.0614\n",
      "Normalized VGI per domain:\n",
      "  Product Quality: 0.677\n",
      "  Aesthetic Attributes: 0.522\n",
      "  Functionality: 0.165\n",
      "  Size & Fit: 0.532\n",
      "  Value Perception: 0.245\n",
      "Global VGI: 0.428\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. Variance Gap Index (VGI)\n",
    "# ============================================================\n",
    "\n",
    "def compute_vgi(df_non_other, domains):\n",
    "    \"\"\"\n",
    "    For each review i and domain d:\n",
    "        p_{i,d} = (# of clauses in domain d for review i) / (# of non-'other' clauses in review i)\n",
    "\n",
    "    Var_d = variance_i( p_{i,d} )\n",
    "    Theoretical max variance on [0,1] is 0.25.\n",
    "    Normalized variance = Var_d / 0.25.\n",
    "    VGI(d) = normalized variance (since survey ideal variance ≈ 0).\n",
    "\n",
    "    Global VGI = average_d VGI(d).\n",
    "    \"\"\"\n",
    "    # Count per review-domain\n",
    "    counts = (\n",
    "        df_non_other.groupby([\"review_id\", \"domain_pred\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reindex(columns=domains, fill_value=0)\n",
    "    )\n",
    "\n",
    "    # Total non-'other' clauses per review\n",
    "    total_per_review = counts.sum(axis=1)\n",
    "\n",
    "    # Avoid division by zero (should not happen after filtering, but safe)\n",
    "    counts = counts[total_per_review > 0]\n",
    "    total_per_review = total_per_review[total_per_review > 0]\n",
    "\n",
    "    # Compute p_{i,d}\n",
    "    p_id = counts.div(total_per_review, axis=0)\n",
    "\n",
    "    # Variance per domain\n",
    "    var_d = p_id.var(axis=0)  # variance across reviews\n",
    "\n",
    "    # Normalize by maximum variance (0.25)\n",
    "    vgi_domain = (var_d / 0.25).to_dict()\n",
    "\n",
    "    # Global VGI as simple average\n",
    "    vgi_global = np.mean(list(vgi_domain.values()))\n",
    "\n",
    "    return var_d.to_dict(), vgi_domain, vgi_global\n",
    "\n",
    "var_d, vgi_domain, vgi_global = compute_vgi(df_non_other, DOMAINS)\n",
    "\n",
    "print(\"\\n=== Variance Gap Index (VGI) ===\")\n",
    "print(\"Raw variances per domain:\")\n",
    "for d in DOMAINS:\n",
    "    print(f\"  {d}: {var_d[d]:.4f}\")\n",
    "print(\"Normalized VGI per domain:\")\n",
    "for d in DOMAINS:\n",
    "    print(f\"  {d}: {vgi_domain[d]:.3f}\")\n",
    "print(f\"Global VGI: {vgi_global:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad15e3db-e29e-41af-a3de-84a9138df8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Review Sparsity Index (RSI) ===\n",
      "Global RSI: 0.701\n",
      "RSI per-review distribution (summary):\n",
      "count    32277.000000\n",
      "mean         0.701478\n",
      "std          0.142206\n",
      "min          0.000000\n",
      "25%          0.600000\n",
      "50%          0.800000\n",
      "75%          0.800000\n",
      "max          0.800000\n",
      "Name: domain_pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. Review Sparsity Index (RSI)\n",
    "# ============================================================\n",
    "\n",
    "def compute_rsi(df_non_other, domains):\n",
    "    \"\"\"\n",
    "    Let D = number of domains = 5\n",
    "    For each review i:\n",
    "        k_i = number of distinct domains (from {DOMAINS}) present at least once.\n",
    "        RSI_i = 1 - (k_i / D)\n",
    "    Overall RSI = mean_i RSI_i\n",
    "    \"\"\"\n",
    "    D = len(domains)\n",
    "\n",
    "    domains_per_review = (\n",
    "        df_non_other.groupby(\"review_id\")[\"domain_pred\"]\n",
    "        .apply(lambda s: set(s) & set(domains))\n",
    "    )\n",
    "\n",
    "    k_i = domains_per_review.apply(len)\n",
    "    rsi_i = 1 - (k_i / D)\n",
    "    rsi_global = rsi_i.mean()\n",
    "\n",
    "    return rsi_global, rsi_i.describe()\n",
    "\n",
    "rsi_global, rsi_desc = compute_rsi(df_non_other, DOMAINS)\n",
    "\n",
    "print(\"\\n=== Review Sparsity Index (RSI) ===\")\n",
    "print(f\"Global RSI: {rsi_global:.3f}\")\n",
    "print(\"RSI per-review distribution (summary):\")\n",
    "print(rsi_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2247dd13-f529-4abd-b95a-aa27ec775b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chi-square Goodness-of-Fit Test ===\n",
      "Domain-wise Observed vs. Expected Counts:\n",
      "  Product Quality: Observed =  23146, Expected = 12633.00\n",
      "  Aesthetic Attributes: Observed =  14997, Expected = 12633.00\n",
      "  Functionality: Observed =   4446, Expected = 12633.00\n",
      "  Size & Fit: Observed =  15227, Expected = 12633.00\n",
      "  Value Perception: Observed =   5349, Expected = 12633.00\n",
      "\n",
      "Chi-square statistic: 19229.330\n",
      "p-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8. Chi-square goodness-of-fit test\n",
    "# ============================================================\n",
    "\n",
    "def compute_chi_square(ocr_counts, p_survey, domains):\n",
    "    \"\"\"\n",
    "    Observed: OCR clause counts per domain.\n",
    "    Expected: T * p_survey[d] for each domain d,\n",
    "              where T = sum of observed counts (non-'other' only).\n",
    "    \"\"\"\n",
    "    observed = np.array([ocr_counts[d] for d in domains], dtype=float)\n",
    "    T = observed.sum()\n",
    "    expected = np.array([p_survey[d] * T for d in domains], dtype=float)\n",
    "\n",
    "    chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
    "    return chi2_stat, p_value, observed, expected\n",
    "\n",
    "chi2_stat, p_value, observed, expected = compute_chi_square(ocr_counts, p_survey, DOMAINS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Print detailed per-domain results\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Chi-square Goodness-of-Fit Test ===\")\n",
    "print(\"Domain-wise Observed vs. Expected Counts:\")\n",
    "for d, obs, exp in zip(DOMAINS, observed, expected):\n",
    "    print(f\"  {d}: Observed = {int(obs):>6}, Expected = {exp:.2f}\")\n",
    "\n",
    "print(f\"\\nChi-square statistic: {chi2_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
